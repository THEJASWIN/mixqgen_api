{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "\n",
    "def scrap(inputLink):\n",
    "\n",
    "    web = DesiredCapabilities.CHROME\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "    driver = webdriver.Remote(\n",
    "        command_executor='http://localhost:4444/wd/hub',\n",
    "        desired_capabilities=web,\n",
    "        options=options)\n",
    "\n",
    "    driver.implicitly_wait(30)\n",
    "    driver.delete_all_cookies()\n",
    "    allContent = []\n",
    "    driver.get(inputLink)\n",
    "\n",
    "    try:\n",
    "        article = driver.find_elements_by_xpath('//*[@id=\"root\"]/div/div[3]/article/div/div/section[1]/div/div')\n",
    "        if len(article)>1:\n",
    "            article_title = article[0].find_elements_by_tag_name(\"h1\")\n",
    "        else:\n",
    "            article = driver.find_elements_by_tag_name('section')\n",
    "            article_title = driver.find_element_by_tag_name('h1')\n",
    "\n",
    "        for data in range(len(article)):\n",
    "            temp_data = article[data].find_elements_by_tag_name(\"p\")\n",
    "            for text in temp_data:\n",
    "                allContent.append(text.text)\n",
    "        allPara = \"\".join(allContent)\n",
    "\n",
    "        '''\n",
    "            The content is been formatted to JSON\n",
    "        '''\n",
    "        \n",
    "        medium = {\"Title\":article_title.text,\"Content\":allPara}\n",
    "        output = json.dumps(medium,indent=2)\n",
    "        output_json = json.loads(output)\n",
    "        '''\n",
    "            Returns the JSON data\n",
    "        '''\n",
    "        return output_json\n",
    "    finally:\n",
    "        print(\"......Exiting Medium.....\")\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "......Exiting Medium.....\n"
     ]
    }
   ],
   "source": [
    "link = input()\n",
    "out = scrap(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my previous article of this series ‚ÄúFundamentals of AI‚Äù, I explained the term Artificial Intelligence from the view point of a common man. If a general overview of ‚ÄòA.I‚Äô is what you are looking for then you can start here. In this article, I will be taking an in-depth tour of A.I and Machine Learning VS Deep Learning.When starting off my data science journey I thought these two terms meant the same thing and that it was all just fancy jargon for Artificial Intelligence. It was not until one of my experienced colleagues asked me to differentiate them, that I realized that I knew nothing of the field I was pursuing (bummer!). This article will serve as a starting point for all those looking for data science jobs or a data science internship, making sure that you don‚Äôt make the same mistakes I did.As mentioned in my previous article, both these approaches to Artificial Intelligence have their differences and uses depending on your situation. Let‚Äôs first talk about them individually and then delve into comparisons.Machine Learning is the basis of Artificial Intelligence and has been around for longer than you can imagine. The first mathematical Machine Learning algorithms were actually developed in the 1940s!!.You can read about the history of Machine Learning here.Machine Learning is the art of training a machine to understand data and making conclusions. When you get buying recommendations on Amazon or a movie recommendation on Netflix, it is all because a Machine Learning algorithm at the back-end analyzed your usage trends based on your historic data and made those recommendations for you.Certain algorithms called clustering algorithms are utilized by certain businesses to group together similar customers, they then use these clusters to create targeted advertisements or products for individual groups.You can read about these clustering algorithms below if interested:medium.comMachine Learning algorithms are usually trained on small datasets and since they are comparatively simpler, they do not require heavy computational power (in comparison to Deep Learning) however due to their simplicity they are unable to draw finer distinctions between given data.If you want to learn about the implementation of ML algorithms, the following links will help;medium.commedium.comThe concept of Neural Network was first introduced during the 1980s, however, at that time people were unfamiliar with its power and potential ‚Äî mostly because it was an absolutely new concept but also because the computers available at the time did not even come close to the type of computing power that we use today to train a Deep Neural Network.1. Why Corporate AI projects fail?2. How AI Will Power the Next Wave of Healthcare Innovation?3. Machine Learning by Using Regression Model4. Top Data Science Platforms in 2021 Other than KaggleToday big tech giants like Google, Amazon, IBM, etc. all utilize Deep Learning to benefit their clients. Their services like Speech-To-Text Transcription, OCR, Chat Bots, etc. all have huge trained Neural Networks at their back. Tesla AI technology is considered state-of-the-art in autonomous cars.In the world of A.I., Deep Learning is the big gun that has revolutionized multiple industries. It has transformed the way our world operated.But how do we differentiate it from Machine Learning? Both Machine Learning and Deep Learning take very different approaches to solve given problems.Machine Learning algorithms look at data as a whole and usually tend to draw decision boundaries between different samples; the caveat here is that since they treat all given input features similarly, a change in one feature (As insignificant as it may be) can cause the model to misclassify the example. A Deep Learning model, on the other hand, consists of multiple layers all of which work on different aspects of the input example. This is also one of the main reasons why a Deep Learning model is trained on a huge dataset (generally 100,000 + samples) because a larger dataset means greater diversity and only multi-layered Deep neural network can take advantage of this diversity and make out the minute distinctions ‚Äî A Machine Learning model fails here.An important caveat to mention here is that as complex a Deep Learning model gets, the higher is its training cost. This includes both time and financial costs. Even a simplistic DL model requires a hefty ‚Äî expensive ‚Äî GPU to train in a reasonable time. Tesla has disclosed that their current model took over 70,000 hours of GPU training!!!.I know I said there will not be any coding examples in this series but a practical comparison is important here to wind up the discussion.I used the Fashion mnist dataset and trained it on a Machine Learning classifier called SVM ‚Äî Important to note, this is one of the most complex ML classifiers ‚Äî and a very simple Convolutional Neural Network ‚Äî the model architecture can be seen in the image below.The 712, 202 total param count may seem like a huge number but just for reference I'll let you know Google‚Äôs latest language model has over 1.6 Trillion parameters, and OpenAIs latest GPT-3 model also has 175 billion such parameters üò¨!!.Ours doesn‚Äôt seem so significant now does it? üòÉ**For a fair comparison, I passed the exact data to both the models and let both of them train on a CPU.**The dataset consisted of a total 0f 70,000 images each of size 28x28.The split was 60,000 for training and 10,000 for validation.The SVM model took several hours to train (3 Hours and 45 Mins to be precise) and the result was a blown-up model that overfitted certain classes and performed extremely poorly ‚Äî It gave a validation accuracy of 10%.The CNN network used is a very basic one, it took around 37 mins to train (Significantly faster than the SVM model) and after 10 epochs we ended with an accuracy of 90.05%!!As evident from the results above; Deep Learning provides much better results however, as mentioned before, this does not mean that it is the right approach for you. The selection of which method to use depends on your problem. When encountering an AI problem, you must always ask yourself the following questions;Answers to these will help you out in narrowing down to what algorithm to use.I hope this article helped clear all your doubts and questions.If you are interested in Data Science or A.I. in general, I write articles explaining different aspects of Artificial Intelligence.moosa-ali.medium.com\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca3dd50bcc18e6c6076b96dc053dc743709d41abddfb6544714a093e6e87823"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('medium': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
